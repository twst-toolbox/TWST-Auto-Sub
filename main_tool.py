import tkinter as tk
from tkinter import filedialog, ttk, messagebox
import cv2
import numpy as np
import srt
import datetime
import threading
import os
import asyncio
from PIL import Image, ImageTk

# å°è¯•å¯¼å…¥ Windows OCR åº“
try:
    from winsdk.windows.media.ocr import OcrEngine
    from winsdk.windows.globalization import Language
    from winsdk.windows.graphics.imaging import SoftwareBitmap
    import winsdk.windows.storage.streams as streams
    HAS_WIN_OCR = True
except ImportError:
    HAS_WIN_OCR = False

# ================= æ ¸å¿ƒç®—æ³•ç±» =================

class VideoProcessor:
    def __init__(self):
        self.ocr_engine = None
        if HAS_WIN_OCR:
            # åˆå§‹åŒ–æ—¥è¯­ OCR å¼•æ“
            lang = Language("ja-JP")
            if OcrEngine.is_language_supported(lang):
                self.ocr_engine = OcrEngine.try_create_from_language(lang)

    async def _run_win_ocr(self, cv2_img):
        """è°ƒç”¨ Windows åŸç”Ÿ OCR"""
        if not self.ocr_engine: return ""
        try:
            # OpenCV (BGR) -> RGB
            rgb_img = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB)
            height, width, _ = rgb_img.shape
            
            # è½¬æ¢ä¸º Windows SoftwareBitmap
            # è¿™é‡Œéœ€è¦ä¸€ç‚¹å­—èŠ‚æµæ“ä½œ
            bytes_data = rgb_img.tobytes()
            data_writer = streams.DataWriter()
            data_writer.write_bytes(bytes_data)
            
            ibuffer = data_writer.detach_buffer()
            software_bitmap = SoftwareBitmap.create_copy_from_buffer(
                ibuffer, 
                winsdk.windows.graphics.imaging.BitmapPixelFormat.RG_B8,
                width, 
                height
            )
            
            # è¯†åˆ«
            result = await self.ocr_engine.recognize_async(software_bitmap)
            return result.text.replace(" ", "") # å»é™¤ç©ºæ ¼
        except Exception as e:
            print(f"OCR Error: {e}")
            return ""

    def ocr_image(self, img):
        """åŒæ­¥åŒ…è£…å¼‚æ­¥OCR"""
        if not HAS_WIN_OCR: return "OCR_NOT_INSTALLED"
        return asyncio.run(self._run_win_ocr(img))

# ================= GUI ä¸»ç¨‹åº =================

class App:
    def __init__(self, root):
        self.root = root
        self.root.title("TWST è‡ªåŠ¨åŒ–ç»¼åˆä½œä¸šå·¥å…· V9.0 (WinOCRé›†æˆç‰ˆ)")
        self.root.geometry("1200x900")
        
        # å‚æ•°
        self.rect_d = [320, 465, 630, 100] 
        self.rect_c = [430, 170, 450, 90]  
        self.rect_b = [100, 100, 150, 150] 
        self.diff_thresh = 3.0
        self.bin_thresh = 130
        
        self.processor = VideoProcessor()
        self.video_path = ""
        self.is_processing = False
        
        self._setup_ui()
        
    def _setup_ui(self):
        # é¡¶éƒ¨
        f_top = tk.Frame(self.root, pady=10)
        f_top.pack(fill=tk.X)
        tk.Button(f_top, text="ğŸ“‚ åŠ è½½è§†é¢‘", command=self.load_video, font=("å¾®è½¯é›…é»‘", 10)).pack(side=tk.LEFT, padx=10)
        self.lbl_info = tk.Label(f_top, text="æœªåŠ è½½", fg="gray")
        self.lbl_info.pack(side=tk.LEFT)
        
        # æ ¸å¿ƒå¼€å…³
        self.var_ocr = tk.BooleanVar(value=False)
        cb_ocr = tk.Checkbutton(f_top, text="å¯ç”¨ Windows OCR (è¯†åˆ«æ—¥è¯­)", variable=self.var_ocr, font=("å¾®è½¯é›…é»‘", 10, "bold"), fg="blue")
        cb_ocr.pack(side=tk.RIGHT, padx=10)
        if not HAS_WIN_OCR:
            cb_ocr.config(state=tk.DISABLED, text="æœªæ£€æµ‹åˆ° Windows OCR åº“")
            
        self.btn_run = tk.Button(f_top, text="â–¶ï¸ å¼€å§‹ä½œä¸š", command=self.start_task, bg="#ddffdd", font=("å¾®è½¯é›…é»‘", 12))
        self.btn_run.pack(side=tk.RIGHT, padx=10)

        # é¢„è§ˆåŒº
        f_mid = tk.Frame(self.root, bg="#222")
        f_mid.pack(fill=tk.BOTH, expand=True, padx=10)
        self.canvas = tk.Canvas(f_mid, bg="black")
        self.canvas.pack(fill=tk.BOTH, expand=True)

        # æ§åˆ¶åŒº
        f_ctrl = tk.Frame(self.root, height=200)
        f_ctrl.pack(fill=tk.X, padx=10, pady=5)
        
        # é€‰é¡¹å¡
        nb = ttk.Notebook(f_ctrl)
        nb.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        self.create_tab(nb, "å¯¹è¯æ¡† (ç»¿)", self.rect_d, 0)
        self.create_tab(nb, "é€‰é¡¹æ¡† (è“)", self.rect_c, 1)
        self.create_tab(nb, "èƒŒæ™¯ (çº¢)", self.rect_b, 2)
        
        # é˜ˆå€¼è®¾ç½®
        f_sets = tk.LabelFrame(f_ctrl, text="æ•æ„Ÿåº¦è®¾ç½®", padx=5)
        f_sets.pack(side=tk.RIGHT, fill=tk.Y, padx=5)
        
        tk.Label(f_sets, text="é˜²è¿è¯»çµæ•åº¦:").pack(anchor="w")
        self.s_diff = tk.Scale(f_sets, from_=0.1, to=10.0, resolution=0.1, orient=tk.HORIZONTAL, command=self.update_preview)
        self.s_diff.set(self.diff_thresh)
        self.s_diff.pack(fill=tk.X)
        
        tk.Label(f_sets, text="æ–‡å­—äº®åº¦é˜ˆå€¼:").pack(anchor="w")
        self.s_bin = tk.Scale(f_sets, from_=50, to=255, orient=tk.HORIZONTAL, command=self.update_preview)
        self.s_bin.set(self.bin_thresh)
        self.s_bin.pack(fill=tk.X)

        # åº•éƒ¨
        f_bot = tk.Frame(self.root)
        f_bot.pack(fill=tk.X, padx=10, pady=5)
        self.s_time = tk.Scale(f_bot, from_=0, to=100, orient=tk.HORIZONTAL, showvalue=0, command=self.on_seek)
        self.s_time.pack(fill=tk.X)
        self.progress = ttk.Progressbar(self.root, mode='determinate')
        self.progress.pack(fill=tk.X)

    def create_tab(self, nb, title, rect_var, rid):
        f = tk.Frame(nb)
        nb.add(f, text=title)
        self.sliders = getattr(self, "sliders", {})
        if rid not in self.sliders: self.sliders[rid] = []
        labels = ["X", "Y", "W", "H"]
        for i in range(4):
            tk.Label(f, text=labels[i]).pack(side=tk.LEFT)
            s = tk.Scale(f, from_=0, to=2000, orient=tk.HORIZONTAL, command=lambda v, x=i, r=rid: self.on_rect(v, x, r))
            s.set(rect_var[i])
            s.pack(side=tk.LEFT, fill=tk.X, expand=True)
            self.sliders[rid].append(s)

    def on_rect(self, val, idx, rid):
        val = int(float(val))
        if rid == 0: self.rect_d[idx] = val
        elif rid == 1: self.rect_c[idx] = val
        elif rid == 2: self.rect_b[idx] = val
        self.update_preview()

    def load_video(self):
        path = filedialog.askopenfilename()
        if not path: return
        self.video_path = path
        self.cap = cv2.VideoCapture(path)
        self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
        self.fps = self.cap.get(cv2.CAP_PROP_FPS)
        w = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        h = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        self.s_time.config(to=self.total_frames)
        self.lbl_info.config(text=os.path.basename(path))
        
        for slist in self.sliders.values():
            for s in slist: s.config(to=max(w, h))
        self.update_preview()

    def on_seek(self, val):
        self.update_preview()

    def update_preview(self, _=None):
        if not self.cap or self.is_processing: return
        self.cap.set(cv2.CAP_PROP_POS_FRAMES, int(self.s_time.get()))
        ret, frame = self.cap.read()
        if ret:
            # ç»˜åˆ¶æ¡†
            x,y,w,h = self.rect_d
            cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)
            x,y,w,h = self.rect_c
            cv2.rectangle(frame, (x,y), (x+w,y+h), (255,255,0), 2)
            x,y,w,h = self.rect_b
            cv2.rectangle(frame, (x,y), (x+w,y+h), (0,0,255), 2)
            
            # æ˜¾ç¤ºäºŒå€¼åŒ–æ•ˆæœ (è¾…åŠ©è°ƒè¯•)
            # è¿™é‡Œä»…å±•ç¤ºç»¿æ¡†åŒºåŸŸçš„äºŒå€¼åŒ–æƒ…å†µ
            roi = frame[y:y+h, x:x+w]
            if roi.size > 0:
                gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
                _, bin = cv2.threshold(gray, self.s_bin.get(), 255, cv2.THRESH_BINARY)
                bin_c = cv2.cvtColor(bin, cv2.COLOR_GRAY2BGR)
                frame[y:y+h, x:x+w] = cv2.addWeighted(roi, 0.5, bin_c, 0.5, 0)

            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = Image.fromarray(frame)
            cw, ch = self.canvas.winfo_width(), self.canvas.winfo_height()
            if cw > 1: img.thumbnail((cw, ch))
            self.photo = ImageTk.PhotoImage(img)
            self.canvas.create_image(cw//2, ch//2, image=self.photo, anchor=tk.CENTER)

    def start_task(self):
        if not self.video_path: return
        self.is_processing = True
        self.btn_run.config(state=tk.DISABLED, text="å¤„ç†ä¸­...")
        threading.Thread(target=self.run_process, daemon=True).start()

    def run_process(self):
        try:
            # å¿«ç…§å‚æ•°
            p_rect_d = list(self.rect_d)
            p_rect_c = list(self.rect_c)
            p_rect_b = list(self.rect_b)
            p_diff = self.s_diff.get() / 100.0
            p_bin = self.s_bin.get()
            do_ocr = self.var_ocr.get()
            
            cap = cv2.VideoCapture(self.video_path)
            subs = []
            
            # çŠ¶æ€æœº
            d_speaking = False
            d_start = 0
            d_peak = 0.0
            # è®°å½•æœ€ä½³OCRå¸§ï¼šåœ¨å¯†åº¦æœ€é«˜çš„æ—¶å€™æŠ“å›¾
            d_best_frame = None
            d_max_density = 0.0
            
            # é€‰é¡¹é€»è¾‘æš‚ç•¥ï¼Œä¸“æ³¨äºå¯¹è¯
            last_dil = None
            kernel = np.ones((3,3), np.uint8)
            
            idx = 0
            while True:
                ret, frame = cap.read()
                if not ret: break
                
                if idx % 50 == 0:
                    prog = (idx / self.total_frames) * 100
                    self.root.after(0, lambda v=prog: self.progress.config(value=v))

                # 1. ç»¿æ¡†å¤„ç†
                x,y,w,h = p_rect_d
                if w==0 or h==0: continue
                
                roi_gray = cv2.cvtColor(frame[y:y+h, x:x+w], cv2.COLOR_BGR2GRAY)
                _, binary = cv2.threshold(roi_gray, p_bin, 255, cv2.THRESH_BINARY_INV) # TWSTæ˜¯é»‘å­—ï¼Œç”¨INV
                dilated = cv2.dilate(binary, kernel, iterations=1)
                
                density = cv2.countNonZero(dilated) / (w * h)
                
                # çªå˜æ£€æµ‹
                diff_score = 0.0
                if last_dil is not None:
                    diff = cv2.absdiff(dilated, last_dil)
                    diff_score = cv2.countNonZero(diff) / (w * h)
                last_dil = dilated.copy()
                
                # 2. çŠ¶æ€åˆ¤æ–­
                if not d_speaking:
                    if density > 0.005:
                        d_speaking = True
                        d_start = idx
                        d_peak = density
                        # é‡ç½®OCRç¼“å­˜
                        d_max_density = density
                        d_best_frame = frame[y:y+h, x:x+w].copy()
                else:
                    if density > d_peak: d_peak = density
                    
                    # æ›´æ–°æœ€ä½³OCRå¸§ï¼šæ‰¾å­—æœ€å¤šã€æœ€æ¸…æ™°çš„ä¸€å¸§
                    if density > d_max_density:
                        d_max_density = density
                        d_best_frame = frame[y:y+h, x:x+w].copy()
                    
                    should_cut = False
                    if density < 0.003: should_cut = True
                    elif density < (d_peak * 0.4) and d_peak > 0.02: should_cut = True
                    elif diff_score > p_diff and (idx - d_start)/self.fps > 0.2: should_cut = True
                    
                    if should_cut:
                        dur = (idx - d_start) / self.fps
                        if dur > 0.2:
                            st = datetime.timedelta(seconds=d_start/self.fps)
                            et = datetime.timedelta(seconds=idx/self.fps)
                            
                            content = f"Line {len(subs)+1}"
                            # === è§¦å‘ OCR ===
                            if do_ocr and d_best_frame is not None:
                                text = self.processor.ocr_image(d_best_frame)
                                if text.strip(): content = text.strip()
                            
                            subs.append(srt.Subtitle(index=len(subs)+1, start=st, end=et, content=content))
                        
                        # è¿è¯»å¤„ç†
                        if density > 0.005:
                            d_speaking = True
                            d_start = idx
                            d_peak = density
                            d_max_density = density
                            d_best_frame = frame[y:y+h, x:x+w].copy()
                        else:
                            d_speaking = False
            
            # ä¿å­˜
            srt_path = os.path.splitext(self.video_path)[0] + "_OCR.srt"
            with open(srt_path, "w", encoding="utf-8") as f:
                f.write(srt.compose(subs))
            
            self.root.after(0, lambda: messagebox.showinfo("å®Œæˆ", f"å·²ç”Ÿæˆå­—å¹•: {srt_path}"))
            
        except Exception as e:
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", str(e)))
        finally:
            self.is_processing = False
            self.root.after(0, lambda: self.btn_run.config(state=tk.NORMAL, text="â–¶ï¸ å¼€å§‹ä½œä¸š"))

if __name__ == "__main__":
    root = tk.Tk()
    app = App(root)
    root.mainloop()
