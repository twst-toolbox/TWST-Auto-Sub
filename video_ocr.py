import tkinter as tk
from tkinter import filedialog, ttk, messagebox
import cv2
import numpy as np
import srt
import datetime
import threading
import os
import asyncio
from PIL import Image, ImageTk

# å°è¯•å¯¼å…¥ Windows OCR åº“
try:
    from winsdk.windows.media.ocr import OcrEngine
    from winsdk.windows.globalization import Language
    from winsdk.windows.graphics.imaging import SoftwareBitmap
    import winsdk.windows.storage.streams as streams
    HAS_WIN_OCR = True
except ImportError:
    HAS_WIN_OCR = False

# ================= æ ¸å¿ƒç®—æ³•ç±» =================

class VideoProcessor:
    def __init__(self):
        self.ocr_engine = None
        if HAS_WIN_OCR:
            # åˆå§‹åŒ–æ—¥è¯­ OCR å¼•æ“
            lang = Language("ja-JP")
            if OcrEngine.is_language_supported(lang):
                self.ocr_engine = OcrEngine.try_create_from_language(lang)

    async def _run_win_ocr(self, cv2_img):
        """è°ƒç”¨ Windows åŸç”Ÿ OCR"""
        if not self.ocr_engine: return ""
        try:
            # OpenCV (BGR) -> RGB
            rgb_img = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB)
            height, width, _ = rgb_img.shape
            
            # è½¬æ¢ä¸º Windows SoftwareBitmap
            # è¿™é‡Œéœ€è¦ä¸€ç‚¹å­—èŠ‚æµæ“ä½œ
            bytes_data = rgb_img.tobytes()
            data_writer = streams.DataWriter()
            data_writer.write_bytes(bytes_data)
            
            ibuffer = data_writer.detach_buffer()
            software_bitmap = SoftwareBitmap.create_copy_from_buffer(
                ibuffer, 
                winsdk.windows.graphics.imaging.BitmapPixelFormat.RG_B8,
                width, 
                height
            )
            
            # è¯†åˆ«
            result = await self.ocr_engine.recognize_async(software_bitmap)
            return result.text.replace(" ", "") # å»é™¤ç©ºæ ¼
        except Exception as e:
            print(f"OCR Error: {e}")
            return ""

    def ocr_image(self, img):
        """åŒæ­¥åŒ…è£…å¼‚æ­¥OCR"""
        if not HAS_WIN_OCR: return "OCR_NOT_INSTALLED"
        return asyncio.run(self._run_win_ocr(img))

# ================= GUI ä¸»ç¨‹åº =================

class App:
    def __init__(self, root):
        self.root = root
        self.root.title("TWST è‡ªåŠ¨åŒ–ç»¼åˆä½œä¸šå·¥å…· V9.0 (WinOCRé›†æˆç‰ˆ)")
        self.root.geometry("1200x900")
        
        # å‚æ•°
        self.rect_d = [320, 465, 630, 100] 
        self.rect_c = [430, 170, 450, 90]  
        self.rect_b = [100, 100, 150, 150] 
        self.diff_thresh = 3.0
        self.bin_thresh = 130
        
        self.processor = VideoProcessor()
        self.video_path = ""
        self.is_processing = False
        
        self._setup_ui()
        
    def _setup_ui(self):
        # é¡¶éƒ¨
        f_top = tk.Frame(self.root, pady=10)
        f_top.pack(fill=tk.X)
        tk.Button(f_top, text="ğŸ“‚ åŠ è½½è§†é¢‘", command=self.load_video, font=("å¾®è½¯é›…é»‘", 10)).pack(side=tk.LEFT, padx=10)
        self.lbl_info = tk.Label(f_top, text="æœªåŠ è½½", fg="gray")
        self.lbl_info.pack(side=tk.LEFT)
        
        # æ ¸å¿ƒå¼€å…³
        self.var_ocr = tk.BooleanVar(value=False)
        cb_ocr = tk.Checkbutton(f_top, text="å¯ç”¨ Windows OCR (è¯†åˆ«æ—¥è¯­)", variable=self.var_ocr, font=("å¾®è½¯é›…é»‘", 10, "bold"), fg="blue")
        cb_ocr.pack(side=tk.RIGHT, padx=10)
        if not HAS_WIN_OCR:
            cb_ocr.config(state=tk.DISABLED, text="æœªæ£€æµ‹åˆ° Windows OCR åº“")
            
        self.btn_run = tk.Button(f_top, text="â–¶ï¸ å¼€å§‹ä½œä¸š", command=self.start_task, bg="#ddffdd", font=("å¾®è½¯é›…é»‘", 12))
        self.btn_run.pack(side=tk.RIGHT, padx=10)

        # é¢„è§ˆåŒº
        f_mid = tk.Frame(self.root, bg="#222")
        f_mid.pack(fill=tk.BOTH, expand=True, padx=10)
        self.canvas = tk.Canvas(f_mid, bg="black")
        self.canvas.pack(fill=tk.BOTH, expand=True)

        # æ§åˆ¶åŒº
        f_ctrl = tk.Frame(self.root, height=200)
        f_ctrl.pack(fill=tk.X, padx=10, pady=5)
        
        # é€‰é¡¹å¡
        nb = ttk.Notebook(f_ctrl)
        nb.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        self.create_tab(nb, "å¯¹è¯æ¡† (ç»¿)", self.rect_d, 0)
        self.create_tab(nb, "é€‰é¡¹æ¡† (è“)", self.rect_c, 1)
        self.create_tab(nb, "èƒŒæ™¯ (çº¢)", self.rect_b, 2)
        
        # é˜ˆå€¼è®¾ç½®
        f_sets = tk.LabelFrame(f_ctrl, text="æ•æ„Ÿåº¦è®¾ç½®", padx=5)
        f_sets.pack(side=tk.RIGHT, fill=tk.Y, padx=5)
        
        tk.Label(f_sets, text="é˜²è¿è¯»çµæ•åº¦:").pack(anchor="w")
        self.s_diff = tk.Scale(f_sets, from_=0.1, to=10.0, resolution=0.1, orient=tk.HORIZONTAL, command=self.update_preview)
        self.s_diff.set(self.diff_thresh)
        self.s_diff.pack(fill=tk.X)
        
        tk.Label(f_sets, text="æ–‡å­—äº®åº¦é˜ˆå€¼:").pack(anchor="w")
        self.s_bin = tk.Scale(f_sets, from_=50, to=255, orient=tk.HORIZONTAL, command=self.update_preview)
        self.s_bin.set(self.bin_thresh)
        self.s_bin.pack(fill=tk.X)

        # åº•éƒ¨
        f_bot = tk.Frame(self.root)
        f_bot.pack(fill=tk.X, padx=10, pady=5)
        self.s_time = tk.Scale(f_bot, from_=0, to=100, orient=tk.HORIZONTAL, showvalue=0, command=self.on_seek)
        self.s_time.pack(fill=tk.X)
        self.progress = ttk.Progressbar(self.root, mode='determinate')
        self.progress.pack(fill=tk.X)

    def create_tab(self, nb, title, rect_var, rid):
        f = tk.Frame(nb)
        nb.add(f, text=title)
        self.sliders = getattr(self, "sliders", {})
        if rid not in self.sliders: self.sliders[rid] = []
        labels = ["X", "Y", "W", "H"]
        for i in range(4):
            tk.Label(f, text=labels[i]).pack(side=tk.LEFT)
            s = tk.Scale(f, from_=0, to=2000, orient=tk.HORIZONTAL, command=lambda v, x=i, r=rid: self.on_rect(v, x, r))
            s.set(rect_var[i])
            s.pack(side=tk.LEFT, fill=tk.X, expand=True)
            self.sliders[rid].append(s)

    def on_rect(self, val, idx, rid):
        val = int(float(val))
        if rid == 0: self.rect_d[idx] = val
        elif rid == 1: self.rect_c[idx] = val
        elif rid == 2: self.rect_b[idx] = val
        self.update_preview()

    def load_video(self):
        path = filedialog.askopenfilename()
        if not path: return
        self.video_path = path
        self.cap = cv2.VideoCapture(path)
        self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
        self.fps = self.cap.get(cv2.CAP_PROP_FPS)
        w = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        h = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        self.s_time.config(to=self.total_frames)
        self.lbl_info.config(text=os.path.basename(path))
        
        for slist in self.sliders.values():
            for s in slist: s.config(to=max(w, h))
        self.update_preview()

    def on_seek(self, val):
        self.update_preview()

    def update_preview(self, _=None):
        if not self.cap or self.is_processing: return
        self.cap.set(cv2.CAP_PROP_POS_FRAMES, int(self.s_time.get()))
        ret, frame = self.cap.read()
        if ret:
            # ç»˜åˆ¶æ¡†
            x,y,w,h = self.rect_d
            cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)
            x,y,w,h = self.rect_c
            cv2.rectangle(frame, (x,y), (x+w,y+h), (255,255,0), 2)
            x,y,w,h = self.rect_b
            cv2.rectangle(frame, (x,y), (x+w,y+h), (0,0,255), 2)
            
            # æ˜¾ç¤ºäºŒå€¼åŒ–æ•ˆæœ (è¾…åŠ©è°ƒè¯•)
            # è¿™é‡Œä»…å±•ç¤ºç»¿æ¡†åŒºåŸŸçš„äºŒå€¼åŒ–æƒ…å†µ
            roi = frame[y:y+h, x:x+w]
            if roi.size > 0:
                gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
                _, bin = cv2.threshold(gray, self.s_bin.get(), 255, cv2.THRESH_BINARY)
                bin_c = cv2.cvtColor(bin, cv2.COLOR_GRAY2BGR)
                frame[y:y+h, x:x+w] = cv2.addWeighted(roi, 0.5, bin_c, 0.5, 0)

            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = Image.fromarray(frame)
            cw, ch = self.canvas.winfo_width(), self.canvas.winfo_height()
            if cw > 1: img.thumbnail((cw, ch))
            self.photo = ImageTk.PhotoImage(img)
            self.canvas.create_image(cw//2, ch//2, image=self.photo, anchor=tk.CENTER)

    def start_task(self):
        if not self.video_path: return
        self.is_processing = True
        self.btn_run.config(state=tk.DISABLED, text="å¤„ç†ä¸­...")
        threading.Thread(target=self.run_process, daemon=True).start()

    def run_process(self):
        try:
            # å¿«ç…§å‚æ•° (é”å®šå½“å‰æ»‘å—è®¾ç½®ï¼Œé˜²æ­¢è¿è¡Œä¸­è¯¯è§¦)
            p_rect_d = list(self.rect_d)
            p_rect_c = list(self.rect_c)
            p_rect_b = list(self.rect_b)
            p_diff = self.s_diff.get() / 100.0
            p_bin = self.s_bin.get()
            do_ocr = self.var_ocr.get()
            
            cap = cv2.VideoCapture(self.video_path)
            subs = []
            
            # --- çŠ¶æ€æœºå˜é‡ ---
            d_speaking = False
            d_start = 0
            d_peak = 0.0
            
            # ã€å…³é”®æ–°å¢ã€‘è®°å½•è¿™å¥è¯â€œæœ€å®Œç¾â€çš„ä¸€å¸§
            d_best_frame = None
            d_max_density_in_sentence = 0.0
            
            last_dil = None
            kernel = np.ones((3,3), np.uint8)
            
            idx = 0
            while True:
                ret, frame = cap.read()
                if not ret: break
                
                if idx % 50 == 0:
                    prog = (idx / self.total_frames) * 100
                    self.root.after(0, lambda v=prog: self.progress.config(value=v))

                # 1. ç»¿æ¡†å¤„ç†
                x,y,w,h = p_rect_d
                if w==0 or h==0: continue
                
                # è£å‰ªå‡ºå¯¹è¯æ¡†åŒºåŸŸ
                roi = frame[y:y+h, x:x+w]
                
                # å›¾åƒå¤„ç†
                roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
                # TWST/18Trip ç™½å­—é»‘å­—é€»è¾‘ä¸åŒï¼Œè¿™é‡Œå‡è®¾ç”¨é€šç”¨çš„é˜ˆå€¼å¤„ç†
                # å¦‚æœæ˜¯18Trip(ç™½å­—)ï¼Œç”¨ THRESH_BINARYï¼›å¦‚æœæ˜¯TWST(é»‘å­—)ï¼Œç”¨ THRESH_BINARY_INV
                # è¿™é‡Œé»˜è®¤ç”¨ INV (TWSTæ¨¡å¼)ï¼Œå¦‚æœä½ ä¸»è¦è·‘18Tï¼Œå¯ä»¥åœ¨ç•Œé¢åŠ ä¸ªå¼€å…³åˆ‡æ¢æ¨¡å¼
                # æš‚ä¸”ç”¨ INV (é»‘å­—æ¨¡å¼) æ¼”ç¤ºï¼Œæˆ–è€…ä½ å¯ä»¥æ ¹æ®äº®åº¦è‡ªåŠ¨åˆ¤æ–­
                # ä¸ºäº†é€šç”¨ï¼Œè¿™é‡Œå‡è®¾ä½ å·²ç»è°ƒæ•´å¥½äº†æ»‘å—èƒ½æŠŠå­—æŠ å‡ºæ¥
                _, binary = cv2.threshold(roi_gray, p_bin, 255, cv2.THRESH_BINARY_INV)
                
                dilated = cv2.dilate(binary, kernel, iterations=1)
                density = cv2.countNonZero(dilated) / (w * h)
                
                # çªå˜æ£€æµ‹
                diff_score = 0.0
                if last_dil is not None:
                    diff = cv2.absdiff(dilated, last_dil)
                    diff_score = cv2.countNonZero(diff) / (w * h)
                last_dil = dilated.copy()
                
                # 2. çŠ¶æ€åˆ¤æ–­
                if not d_speaking:
                    # === å¼€å§‹è¯´è¯ ===
                    if density > 0.005:
                        d_speaking = True
                        d_start = idx
                        d_peak = density
                        
                        # åˆå§‹åŒ–æœ€ä½³å¸§ï¼šåˆšå¼€å§‹è¯´è¯ï¼Œå½“å‰å¸§å°±æ˜¯æœ€ä½³
                        d_max_density_in_sentence = density
                        d_best_frame = roi.copy() 
                else:
                    # === è¯´è¯ä¸­ ===
                    if density > d_peak: d_peak = density
                    
                    # ã€æ ¸å¿ƒé€»è¾‘ã€‘æ›´æ–°æœ€ä½³å¸§
                    # å¦‚æœå½“å‰å¸§çš„å­—æ•°æ¯”ä¹‹å‰è®°å½•çš„è¿˜å¤šï¼Œæˆ–è€…å·®ä¸å¤šå¤šä½†ç”»é¢æ›´ç¨³å®š
                    # æˆ‘ä»¬å°±è®¤ä¸ºå½“å‰å¸§æ˜¯æ›´å¥½çš„OCRç´ æ
                    # (åŠ  0.001 çš„ç¼“å†²æ˜¯ä¸ºäº†é˜²æ­¢å¾®å°æŠ–åŠ¨é¢‘ç¹æ›´æ–°)
                    if density > d_max_density_in_sentence + 0.001:
                        d_max_density_in_sentence = density
                        d_best_frame = roi.copy() # å¿…é¡»ç”¨ copy() å­˜å…¥å†…å­˜
                    
                    # === ç»“æŸåˆ¤å®š ===
                    should_cut = False
                    
                    # æ¡ä»¶1: æ²¡å­—äº†
                    if density < 0.003: should_cut = True
                    # æ¡ä»¶2: å­—çªç„¶å˜å°‘ (å³°å€¼å›è½)
                    elif density < (d_peak * 0.4) and d_peak > 0.02: should_cut = True
                    # æ¡ä»¶3: å­—çš„å½¢çŠ¶çªå˜ (é˜²è¿è¯»)
                    elif diff_score > p_diff and (idx - d_start)/self.fps > 0.2: should_cut = True
                    
                    if should_cut:
                        dur = (idx - d_start) / self.fps
                        if dur > 0.2:
                            st = datetime.timedelta(seconds=d_start/self.fps)
                            et = datetime.timedelta(seconds=idx/self.fps)
                            
                            content = f"Line {len(subs)+1}"
                            
                            # === è§¦å‘ OCR (ä½¿ç”¨ç¼“å­˜çš„æœ€ä½³å¸§) ===
                            if do_ocr and d_best_frame is not None:
                                # æ³¨æ„ï¼šOCRå¾ˆè€—æ—¶ï¼Œè¿™é‡Œæ˜¯å•çº¿ç¨‹ä¼šå¡é¡¿ç•Œé¢
                                # ä½†ä¸ºäº†æ•°æ®å‡†ç¡®ï¼Œå¿…é¡»ç­‰OCRå®Œæˆ
                                text = self.processor.ocr_image(d_best_frame)
                                if text.strip(): content = text.strip()
                            
                            subs.append(srt.Subtitle(index=len(subs)+1, start=st, end=et, content=content))
                        
                        # è¿è¯»å¤„ç†ï¼šå¦‚æœåˆ‡æ–­æ—¶å±å¹•ä¸Šè¿˜æœ‰å­—ï¼Œè¯´æ˜æ˜¯è¿è¯»
                        if density > 0.005:
                            d_speaking = True
                            d_start = idx
                            d_peak = density
                            # é‡ç½®æœ€ä½³å¸§ä¸ºå½“å‰æ–°å¥å­çš„ç¬¬ä¸€å¸§
                            d_max_density_in_sentence = density
                            d_best_frame = roi.copy()
                        else:
                            d_speaking = False
            
            # ä¿å­˜ SRT
            base_name = os.path.splitext(self.video_path)[0]
            suffix = "_OCR.srt" if do_ocr else ".srt"
            srt_path = base_name + suffix
            
            with open(srt_path, "w", encoding="utf-8") as f:
                f.write(srt.compose(subs))
            
            self.root.after(0, lambda: messagebox.showinfo("å®Œæˆ", f"å·²ç”Ÿæˆå­—å¹•: {srt_path}"))
            
        except Exception as e:
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", str(e)))
        finally:
            self.is_processing = False
            self.root.after(0, lambda: self.btn_run.config(state=tk.NORMAL, text="â–¶ï¸ å¼€å§‹ä½œä¸š"))

if __name__ == "__main__":
    root = tk.Tk()
    app = App(root)
    root.mainloop()
