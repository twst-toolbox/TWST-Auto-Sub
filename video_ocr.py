import tkinter as tk
from tkinter import filedialog, ttk, messagebox
import cv2
import numpy as np
import srt
import datetime
import threading
import os
import asyncio
import traceback
from PIL import Image, ImageTk

# --- Windows OCR æ¨¡å—å¯¼å…¥ ---
HAS_WIN_OCR = False
try:
    from winsdk.windows.media.ocr import OcrEngine
    from winsdk.windows.globalization import Language
    from winsdk.windows.graphics.imaging import SoftwareBitmap, BitmapPixelFormat
    import winsdk.windows.storage.streams as streams
    HAS_WIN_OCR = True
except ImportError:
    print("æœªå®‰è£… winsdk åº“æˆ–ä¸åœ¨ Windows ç¯å¢ƒ")

# ================= æ ¸å¿ƒç®—æ³•ç±» =================
class VideoProcessor:
    def __init__(self, logger):
        self.ocr_engine = None
        self.logger = logger
        if HAS_WIN_OCR:
            try:
                lang = Language("ja-JP")
                if OcrEngine.is_language_supported(lang):
                    self.ocr_engine = OcrEngine.try_create_from_language(lang)
                    self.logger("âœ… [ç³»ç»Ÿ] Windows OCR (æ—¥è¯­) å°±ç»ªã€‚")
                else:
                    self.logger("âš ï¸ [ç³»ç»Ÿ] OCR åˆå§‹åŒ–å¤±è´¥ï¼šæ‚¨çš„ Windows å¯èƒ½æœªå®‰è£…æ—¥è¯­è¯­è¨€åŒ…ã€‚")
            except Exception as e:
                self.logger(f"âŒ [ç³»ç»Ÿ] OCR åˆå§‹åŒ–å¼‚å¸¸: {e}")

    async def _run_win_ocr(self, cv2_img):
        if not self.ocr_engine: return ""
        try:
            # âœ… ä¿®æ­£1: BGR â†’ BGRA (å¿…é¡»4é€šé“æ‰èƒ½ç”¨ Bgra8 æ ¼å¼)
            bgra_img = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2BGRA)
            height, width = bgra_img.shape[:2]

            bytes_data = bgra_img.tobytes()
            data_writer = streams.DataWriter()
            data_writer.write_bytes(bytes_data)
            ibuffer = data_writer.detach_buffer()

            # âœ… ä¿®æ­£2: RG_B8 æ ¹æœ¬ä¸å­˜åœ¨ï¼Œæ­£ç¡®æšä¸¾æ˜¯ Bgra8
            software_bitmap = SoftwareBitmap.create_copy_from_buffer(
                ibuffer,
                BitmapPixelFormat.BGRA8,  # â† æ ¸å¿ƒä¿®æ­£
                width,
                height
            )

            result = await self.ocr_engine.recognize_async(software_bitmap)
            return result.text.replace(" ", "")
        except Exception as e:
            self.logger(f"âš ï¸ [OCRå†…éƒ¨é”™è¯¯] {e}")
            return ""

    def ocr_image(self, img):
        if not HAS_WIN_OCR: return ""
        try:
            return asyncio.run(self._run_win_ocr(img))
        except Exception:
            return ""

# ================= GUI ä¸»ç¨‹åº =================
class App:
    def __init__(self, root):
        self.root = root
        self.root.title("Video Subtitle Extractor V10.2 (OCRä¿®æ­£+ç™½å±è¿‡æ»¤)")
        self.root.geometry("1280x900")

        self.rect_d = [320, 465, 630, 100]  # å¯¹è¯(ç»¿)
        self.rect_c = [430, 170, 450, 90]   # é€‰é¡¹(è“)
        self.rect_b = [100, 100, 150, 150]  # èƒŒæ™¯(çº¢) â€” ç”¨äºç™½å±æ£€æµ‹

        self.video_path = ""
        self.cap = None
        self.total_frames = 0
        self.fps = 30
        self.is_processing = False

        self._setup_ui()
        self.processor = VideoProcessor(self.log)

    def log(self, message):
        self.txt_log.config(state=tk.NORMAL)
        self.txt_log.insert(tk.END, message + "\n")
        self.txt_log.see(tk.END)
        self.txt_log.config(state=tk.DISABLED)

    def _setup_ui(self):
        # é¡¶éƒ¨
        f_top1 = tk.Frame(self.root, pady=5)
        f_top1.pack(fill=tk.X, padx=10)
        tk.Button(f_top1, text="ğŸ“‚ åŠ è½½è§†é¢‘", command=self.load_video, font=("å¾®è½¯é›…é»‘", 10)).pack(side=tk.LEFT)
        self.lbl_info = tk.Label(f_top1, text="æœªåŠ è½½...", fg="blue")
        self.lbl_info.pack(side=tk.LEFT, padx=10)

        f_top2 = tk.Frame(self.root, pady=5)
        f_top2.pack(fill=tk.X, padx=10)

        self.var_mode = tk.StringVar(value="BLACK")
        tk.Label(f_top2, text="æ¨¡å¼:", font=("å¾®è½¯é›…é»‘", 10, "bold")).pack(side=tk.LEFT)
        tk.Radiobutton(f_top2, text="TWST (é»‘å­—)", variable=self.var_mode, value="BLACK").pack(side=tk.LEFT)
        tk.Radiobutton(f_top2, text="18TRIP (ç™½å­—)", variable=self.var_mode, value="WHITE").pack(side=tk.LEFT, padx=10)

        self.var_ocr = tk.BooleanVar(value=False)
        cb_ocr = tk.Checkbutton(f_top2, text="å¯ç”¨ OCR", variable=self.var_ocr, font=("å¾®è½¯é›…é»‘", 10, "bold"), fg="purple")
        cb_ocr.pack(side=tk.LEFT, padx=20)
        if not HAS_WIN_OCR: cb_ocr.config(state=tk.DISABLED, text="OCRä¸å¯ç”¨(ç¼ºwinsdk)")

        self.btn_run = tk.Button(f_top2, text="â–¶ï¸ å¼€å§‹å¤„ç†", command=self.start_task, bg="#ddffdd", font=("å¾®è½¯é›…é»‘", 11, "bold"))
        self.btn_run.pack(side=tk.RIGHT)
        self.btn_stop = tk.Button(f_top2, text="ğŸ›‘ åœæ­¢", command=self.stop_task, bg="#ffdddd", font=("å¾®è½¯é›…é»‘", 11), state=tk.DISABLED)
        self.btn_stop.pack(side=tk.RIGHT, padx=10)

        # ä¸­é—´
        f_mid = tk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        f_mid.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)

        self.canvas_frame = tk.Frame(f_mid, bg="#222")
        f_mid.add(self.canvas_frame, stretch="always")
        self.canvas = tk.Canvas(self.canvas_frame, bg="black")
        self.canvas.pack(fill=tk.BOTH, expand=True)

        f_log = tk.Frame(f_mid)
        f_mid.add(f_log, width=350)
        tk.Label(f_log, text="ğŸ“œ è¿è¡Œæ—¥å¿—").pack(anchor="w")
        self.txt_log = tk.Text(f_log, bg="#1e1e1e", fg="#00ff00", font=("Consolas", 9), state=tk.DISABLED)
        self.txt_log.pack(fill=tk.BOTH, expand=True)

        # åº•éƒ¨å‚æ•°
        f_ctrl = tk.Frame(self.root, height=150)
        f_ctrl.pack(fill=tk.X, padx=10, pady=5)

        nb = ttk.Notebook(f_ctrl)
        nb.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        self.create_tab(nb, "å¯¹è¯æ¡†(ç»¿)", self.rect_d, 0)
        self.create_tab(nb, "é€‰é¡¹æ¡†(è“)", self.rect_c, 1)
        self.create_tab(nb, "èƒŒæ™¯(çº¢)", self.rect_b, 2)

        f_sets = tk.LabelFrame(f_ctrl, text="è®¾ç½®", padx=5)
        f_sets.pack(side=tk.RIGHT, fill=tk.Y, padx=5)

        tk.Label(f_sets, text="é˜²è¿è¯»çµæ•åº¦:").pack(anchor="w")
        self.s_diff = tk.Scale(f_sets, from_=0.1, to=10.0, resolution=0.1, orient=tk.HORIZONTAL)
        self.s_diff.set(3.0)
        self.s_diff.pack(fill=tk.X)

        tk.Label(f_sets, text="æ–‡å­—é˜ˆå€¼:").pack(anchor="w")
        self.s_bin = tk.Scale(f_sets, from_=50, to=255, orient=tk.HORIZONTAL, command=self.update_preview)
        self.s_bin.set(130)
        self.s_bin.pack(fill=tk.X)

        # âœ… æ–°å¢ï¼šç™½å±äº®åº¦é˜ˆå€¼æ»‘æ¡
        tk.Label(f_sets, text="ç™½å±è¿‡æ»¤é˜ˆå€¼(çº¢æ¡†):").pack(anchor="w")
        self.s_white = tk.Scale(f_sets, from_=150, to=255, orient=tk.HORIZONTAL)
        self.s_white.set(220)
        self.s_white.pack(fill=tk.X)

        f_bot = tk.Frame(self.root)
        f_bot.pack(side=tk.BOTTOM, fill=tk.X, padx=10, pady=10)
        self.s_time = tk.Scale(f_bot, from_=0, to=100, orient=tk.HORIZONTAL, showvalue=0, command=self.on_seek)
        self.s_time.pack(fill=tk.X)
        self.progress = ttk.Progressbar(f_bot, mode='determinate')
        self.progress.pack(fill=tk.X, pady=5)

    def create_tab(self, nb, title, rect_var, rid):
        f = tk.Frame(nb)
        nb.add(f, text=title)
        self.sliders = getattr(self, "sliders", {})
        if rid not in self.sliders: self.sliders[rid] = []
        labels = ["X", "Y", "W", "H"]
        for i in range(4):
            tk.Label(f, text=labels[i]).pack(side=tk.LEFT, padx=2)
            s = tk.Scale(f, from_=0, to=2000, orient=tk.HORIZONTAL, command=lambda v, x=i, r=rid: self.on_rect(v, x, r))
            s.set(rect_var[i])
            s.pack(side=tk.LEFT, fill=tk.X, expand=True)
            self.sliders[rid].append(s)

    def on_rect(self, val, idx, rid):
        val = int(float(val))
        if rid == 0: self.rect_d[idx] = val
        elif rid == 1: self.rect_c[idx] = val
        elif rid == 2: self.rect_b[idx] = val
        self.update_preview()

    def load_video(self):
        path = filedialog.askopenfilename()
        if not path: return
        self.video_path = path
        self.cap = cv2.VideoCapture(path)
        self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
        self.fps = self.cap.get(cv2.CAP_PROP_FPS)
        w = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        h = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        self.s_time.config(to=self.total_frames)
        self.lbl_info.config(text=f"{os.path.basename(path)} ({w}x{h})")
        for slist in self.sliders.values():
            for s in slist: s.config(to=max(w, h))
        self.update_preview()

    def on_seek(self, val):
        self.update_preview()

    def update_preview(self, _=None):
        if not self.cap or self.is_processing: return
        self.cap.set(cv2.CAP_PROP_POS_FRAMES, int(self.s_time.get()))
        ret, frame = self.cap.read()
        if ret:
            x, y, w, h = self.rect_d
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)      # ç»¿
            xc, yc, wc, hc = self.rect_c
            cv2.rectangle(frame, (xc, yc), (xc+wc, yc+hc), (255, 255, 0), 2)  # è“
            xb, yb, wb, hb = self.rect_b
            cv2.rectangle(frame, (xb, yb), (xb+wb, yb+hb), (0, 0, 255), 2)   # çº¢

            roi = frame[y:y+h, x:x+w]
            if roi.size > 0:
                gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
                mode = cv2.THRESH_BINARY_INV if self.var_mode.get() == "BLACK" else cv2.THRESH_BINARY
                _, bin_img = cv2.threshold(gray, self.s_bin.get(), 255, mode)
                bin_c = cv2.cvtColor(bin_img, cv2.COLOR_GRAY2BGR)
                frame[y:y+h, x:x+w] = cv2.addWeighted(roi, 0.3, bin_c, 0.7, 0)

            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = Image.fromarray(frame)
            cw, ch = self.canvas.winfo_width(), self.canvas.winfo_height()
            if cw > 1: img.thumbnail((cw, ch))
            self.photo = ImageTk.PhotoImage(img)
            self.canvas.create_image(cw//2, ch//2, image=self.photo, anchor=tk.CENTER)

    def stop_task(self):
        self.is_processing = False
        self.log("âš ï¸ åœæ­¢...")

    def start_task(self):
        if not self.video_path: return
        self.is_processing = True
        self.btn_run.config(state=tk.DISABLED, text="å¤„ç†ä¸­...")
        self.btn_stop.config(state=tk.NORMAL)
        self.log("\nğŸš€ === å¼€å§‹ä»»åŠ¡ ===")
        threading.Thread(target=self.run_process, daemon=True).start()

    def is_white_flash(self, frame, rect, threshold):
        """
        âœ… çº¢æ¡†ç™½å±æ£€æµ‹
        åˆ¤æ–­èƒŒæ™¯åŒºåŸŸå¹³å‡äº®åº¦æ˜¯å¦è¶…è¿‡é˜ˆå€¼ï¼Œè¶…è¿‡è¯´æ˜æ˜¯æ¼”å‡ºç™½å±ï¼Œåº”å¿½ç•¥è¯¥å¸§ã€‚
        """
        xb, yb, wb, hb = rect
        if wb <= 0 or hb <= 0: return False
        roi_b = frame[yb:yb+hb, xb:xb+wb]
        if roi_b.size == 0: return False
        gray_b = cv2.cvtColor(roi_b, cv2.COLOR_BGR2GRAY)
        mean_brightness = cv2.mean(gray_b)[0]
        return mean_brightness >= threshold

    def _save_dialogue(self, subs, d_start, d_end_idx, d_best_frame, sub_index, do_ocr):
        """å¯¾è©±ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç¢ºå®šã—ã¦ãƒªã‚¹ãƒˆã«è¿½åŠ ã™ã‚‹å…±é€šé–¢æ•°"""
        dur = (d_end_idx - d_start) / self.fps
        if dur < 0.3:
            return sub_index  # çŸ­ã™ãã‚‹ã‚‚ã®ã¯ç„¡è¦–ï¼ˆ0.25â†’0.3ã«å¾®èª¿æ•´ï¼‰
        st = datetime.timedelta(seconds=d_start / self.fps)
        et = datetime.timedelta(seconds=d_end_idx / self.fps)
        content = ""
        if do_ocr and d_best_frame is not None:
            try:
                text = self.processor.ocr_image(d_best_frame)
                # âœ… 2æ–‡å­—æœªæº€ã®OCRçµæœã¯ãƒã‚¤ã‚ºã¨åˆ¤æ–­ã—ã¦ç„¡è¦–
                if text and len(text.strip()) >= 2:
                    content = text
            except: pass
        if not content:
            content = f"Line {sub_index}"
        # âœ… ç›´å‰ã‚¨ãƒ³ãƒˆãƒªã¨å…¨ãåŒã˜ãƒ†ã‚­ã‚¹ãƒˆãªã‚‰é‡è¤‡è¿½åŠ ã—ãªã„
        if subs and subs[-1].content == content and content.startswith("Line "):
            return sub_index  # ã€ŒLine Nã€ã®é€£ç¶šé‡è¤‡ã¯ã‚¹ã‚­ãƒƒãƒ—
        subs.append(srt.Subtitle(index=sub_index, start=st, end=et, content=content))
        self.log(f"âœ… [L{sub_index}] å¯¾è©±: {content[:20]}...")
        return sub_index + 1

    def _save_choice(self, subs, c_start, c_end_idx, sub_index, do_ocr, p_rect_c, p_bin):
        """é¸æŠè‚¢ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç¢ºå®šã—ã¦ãƒªã‚¹ãƒˆã«è¿½åŠ ã™ã‚‹å…±é€šé–¢æ•°"""
        dur_c = (c_end_idx - c_start) / self.fps
        if dur_c < 0.5:
            return sub_index
        st = datetime.timedelta(seconds=c_start / self.fps)
        et = datetime.timedelta(seconds=c_end_idx / self.fps)
        content = ""
        if do_ocr:
            xc, yc, wc, hc = p_rect_c
            cap2 = cv2.VideoCapture(self.video_path)
            cap2.set(cv2.CAP_PROP_POS_FRAMES, c_start + 5)
            ret_c, frame_c = cap2.read()
            cap2.release()
            if ret_c:
                roi_ocr_c = frame_c[yc:yc+hc, xc:xc+wc]
                text_c = self.processor.ocr_image(roi_ocr_c)
                if text_c: content = text_c
        if not content:
            content = f"[Choice] Line {sub_index}"
        else:
            content = f"[é¸é …] {content}"
        subs.append(srt.Subtitle(index=sub_index, start=st, end=et, content=content))
        self.log(f"ğŸ”¹ [L{sub_index}] {content[:30]}")
        return sub_index + 1

    def run_process(self):
        try:
            p_rect_d = list(self.rect_d)
            p_rect_c = list(self.rect_c)
            p_rect_b = list(self.rect_b)
            p_diff = self.s_diff.get() / 100.0
            p_bin = self.s_bin.get()
            p_white = self.s_white.get()
            do_ocr = self.var_ocr.get()
            is_black_text = (self.var_mode.get() == "BLACK")
            mode = cv2.THRESH_BINARY_INV if is_black_text else cv2.THRESH_BINARY

            cap = cv2.VideoCapture(self.video_path)
            total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            subs = []

            # --- å¯¾è©±ã‚¹ãƒ†ãƒ¼ãƒˆ ---
            d_speaking = False
            d_start = 0
            d_peak = 0.0
            d_best_frame = None
            d_max_den = 0.0
            last_dil = None

            # --- é¸æŠè‚¢ã‚¹ãƒ†ãƒ¼ãƒˆ ---
            c_active = False
            c_start = 0

            sub_index = 1
            kernel = np.ones((3, 3), np.uint8)
            xc, yc, wc, hc = p_rect_c

            idx = 0
            while self.is_processing:
                ret, frame = cap.read()
                if not ret: break

                if idx % 100 == 0:
                    prog = (idx / total) * 100
                    self.root.after(0, lambda v=prog: self.progress.config(value=v))

                # ===== ç™½å±æ¤œå‡º: å…¨ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ— =====
                if self.is_white_flash(frame, p_rect_b, p_white):
                    if d_speaking:
                        sub_index = self._save_dialogue(subs, d_start, idx, d_best_frame, sub_index, do_ocr)
                        d_speaking = False
                        last_dil = None
                    if c_active:
                        sub_index = self._save_choice(subs, c_start, idx, sub_index, do_ocr, p_rect_c, p_bin)
                        c_active = False
                    idx += 1
                    continue

                # ===== Step1: å…ˆã«é¸æŠè‚¢ã‚’åˆ¤å®š =====
                is_choice_frame = False
                if wc > 0 and hc > 0:
                    roi_c = frame[yc:yc+hc, xc:xc+wc]
                    gray_c = cv2.cvtColor(roi_c, cv2.COLOR_BGR2GRAY)
                    _, bin_c_img = cv2.threshold(gray_c, p_bin, 255, mode)
                    den_c = cv2.countNonZero(bin_c_img) / (wc * hc)
                    is_choice_frame = (den_c > 0.1)

                # ===== Step2: ç›¸äº’æ’ä»– â€” é¸æŠè‚¢ãƒ•ãƒ¬ãƒ¼ãƒ ãªã‚‰å¯¾è©±ã‚’å¼·åˆ¶çµ‚äº† =====
                if is_choice_frame:
                    # å¯¾è©±ãŒé€²è¡Œä¸­ãªã‚‰ç· ã‚ã‚‹
                    if d_speaking:
                        sub_index = self._save_dialogue(subs, d_start, idx, d_best_frame, sub_index, do_ocr)
                        d_speaking = False
                        last_dil = None

                    # é¸æŠè‚¢ã‚¹ãƒ†ãƒ¼ãƒˆãƒã‚·ãƒ³
                    if not c_active:
                        c_active = True
                        c_start = idx
                    # é¸æŠè‚¢ç¶™ç¶šä¸­ã¯ä½•ã‚‚ã—ãªã„ï¼ˆçµ‚äº†ã¯æ¬¡ã®elseã§å‡¦ç†ï¼‰

                else:
                    # ===== é¸æŠè‚¢ãƒ•ãƒ¬ãƒ¼ãƒ ã§ãªã„ â†’ é¸æŠè‚¢ãŒçµ‚ã‚ã£ãŸã‹ç¢ºèª =====
                    if c_active:
                        sub_index = self._save_choice(subs, c_start, idx, sub_index, do_ocr, p_rect_c, p_bin)
                        c_active = False
                        # âœ… é¸æŠè‚¢çµ‚äº†å¾Œã¯å·®åˆ†è¨ˆç®—ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆé¸æŠè‚¢å‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¨æ¯”ã¹ã¦ã—ã¾ã†ã®ã‚’é˜²ãï¼‰
                        last_dil = None

                    # ===== Step3: å¯¾è©±æ¤œå‡ºï¼ˆé¸æŠè‚¢ãƒ•ãƒ¬ãƒ¼ãƒ ã§ãªã„ã¨ãã ã‘ï¼‰ =====
                    x, y, w, h = p_rect_d
                    if w > 0 and h > 0:
                        roi = frame[y:y+h, x:x+w]
                        roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
                        _, binary = cv2.threshold(roi_gray, p_bin, 255, mode)
                        dilated = cv2.dilate(binary, kernel, iterations=1)
                        density = cv2.countNonZero(dilated) / (w * h)

                        diff_score = 0.0
                        if last_dil is not None:
                            diff_score = cv2.countNonZero(cv2.absdiff(dilated, last_dil)) / (w * h)
                        last_dil = dilated.copy()

                        if not d_speaking:
                            if density > 0.005:
                                d_speaking = True
                                d_start = idx
                                d_peak = density
                                d_max_den = density
                                d_best_frame = roi.copy()
                        else:
                            if density > d_peak: d_peak = density
                            if density > d_max_den + 0.001:
                                d_max_den = density
                                d_best_frame = roi.copy()

                            should_cut = False
                            if density < 0.002: should_cut = True
                            elif density < (d_peak * 0.4) and d_peak > 0.02: should_cut = True
                            elif diff_score > p_diff and (idx - d_start) / self.fps > 0.2: should_cut = True

                            if should_cut:
                                sub_index = self._save_dialogue(subs, d_start, idx, d_best_frame, sub_index, do_ocr)
                                if density > 0.005:
                                    d_speaking = True
                                    d_start = idx
                                    d_peak = density
                                    d_max_den = density
                                    d_best_frame = roi.copy()
                                else:
                                    d_speaking = False

                idx += 1

            # ===== ãƒ«ãƒ¼ãƒ—çµ‚äº†å¾Œã€æœªç¢ºå®šã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç· ã‚ã‚‹ =====
            if d_speaking:
                self._save_dialogue(subs, d_start, idx, d_best_frame, sub_index, do_ocr)
            if c_active:
                self._save_choice(subs, c_start, idx, sub_index, do_ocr, p_rect_c, p_bin)

            cap.release()

            # æ™‚ç³»åˆ—ã‚½ãƒ¼ãƒˆ â†’ é€£ç•ªæŒ¯ã‚Šç›´ã—
            subs.sort(key=lambda x: x.start)
            for i, sub in enumerate(subs): sub.index = i + 1

            srt_path = os.path.splitext(self.video_path)[0] + ("_OCR.srt" if do_ocr else ".srt")
            with open(srt_path, "w", encoding="utf-8-sig") as f:
                f.write(srt.compose(subs))

            self.root.after(0, lambda: messagebox.showinfo("å®Œæˆ", f"æ–‡ä»¶å·²ä¿å­˜:\n{srt_path}"))

        except Exception as e:
            self.log(f"âŒ é”™è¯¯: {e}")
            print(traceback.format_exc())
        finally:
            self.is_processing = False
            self.root.after(0, lambda: self.btn_run.config(state=tk.NORMAL, text="â–¶ï¸ å¼€å§‹å¤„ç†"))

if __name__ == "__main__":
    root = tk.Tk()
    app = App(root)
    root.mainloop()
