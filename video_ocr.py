import tkinter as tk
from tkinter import filedialog, ttk, messagebox
import cv2
import numpy as np
import srt
import datetime
import threading
import os
import asyncio
import traceback
from PIL import Image, ImageTk

# --- Windows OCR æ¨¡å—å¯¼å…¥ ---
HAS_WIN_OCR = False
try:
    from winsdk.windows.media.ocr import OcrEngine
    from winsdk.windows.globalization import Language
    from winsdk.windows.graphics.imaging import SoftwareBitmap, BitmapPixelFormat
    import winsdk.windows.storage.streams as streams
    HAS_WIN_OCR = True
except ImportError:
    print("æœªå®‰è£… winsdk åº“æˆ–ä¸åœ¨ Windows ç¯å¢ƒ")

# ================= æ ¸å¿ƒç®—æ³•ç±» =================
class VideoProcessor:
    def __init__(self, logger):
        self.ocr_engine = None
        self.logger = logger
        if HAS_WIN_OCR:
            try:
                lang = Language("ja-JP")
                if OcrEngine.is_language_supported(lang):
                    self.ocr_engine = OcrEngine.try_create_from_language(lang)
                    self.logger("âœ… [ç³»ç»Ÿ] Windows OCR (æ—¥è¯­) å°±ç»ªã€‚")
                else:
                    self.logger("âš ï¸ [ç³»ç»Ÿ] OCR åˆå§‹åŒ–å¤±è´¥ï¼šæœªå®‰è£…æ—¥è¯­è¯­è¨€åŒ…ã€‚")
            except Exception as e:
                self.logger(f"âŒ [ç³»ç»Ÿ] OCR åˆå§‹åŒ–å¼‚å¸¸: {e}")

    async def _run_win_ocr(self, cv2_img):
        if not self.ocr_engine:
            return ""
        try:
            # BGR è½¬ BGRA (å¿…é¡»4é€šé“æ‰èƒ½ç”¨ BGRA8 æ ¼å¼)
            bgra_img = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2BGRA)
            height, width = bgra_img.shape[:2]

            bytes_data = bgra_img.tobytes()
            data_writer = streams.DataWriter()
            data_writer.write_bytes(bytes_data)
            ibuffer = data_writer.detach_buffer()

            software_bitmap = SoftwareBitmap.create_copy_from_buffer(
                ibuffer,
                BitmapPixelFormat.BGRA8,
                width,
                height
            )

            result = await self.ocr_engine.recognize_async(software_bitmap)
            return result.text.replace(" ", "")
        except Exception as e:
            return ""

    def ocr_image(self, img):
        if not HAS_WIN_OCR:
            return ""
        try:
            return asyncio.run(self._run_win_ocr(img))
        except Exception:
            return ""

# ================= GUI ä¸»ç¨‹åº =================
class App:
    def __init__(self, root):
        self.root = root
        self.root.title("Video Subtitle Extractor V12 (é€‰é¡¹é™æ­¢ä¾¦æµ‹ç‰ˆ)")
        self.root.geometry("1280x900")

        self.rect_d =[320, 465, 630, 100]  
        self.rect_c =[430, 170, 450, 90]   
        self.rect_b = [100, 100, 150, 150]  

        self.video_path = ""
        self.cap = None
        self.total_frames = 0
        self.fps = 30
        self.is_processing = False

        self._setup_ui()
        self.processor = VideoProcessor(self.log)

    def log(self, message):
        self.txt_log.config(state=tk.NORMAL)
        self.txt_log.insert(tk.END, message + "\n")
        self.txt_log.see(tk.END)
        self.txt_log.config(state=tk.DISABLED)

    def _setup_ui(self):
        f_top1 = tk.Frame(self.root, pady=5)
        f_top1.pack(fill=tk.X, padx=10)
        tk.Button(f_top1, text="ğŸ“‚ åŠ è½½è§†é¢‘", command=self.load_video, font=("å¾®è½¯é›…é»‘", 10)).pack(side=tk.LEFT)
        self.lbl_info = tk.Label(f_top1, text="æœªåŠ è½½...", fg="blue")
        self.lbl_info.pack(side=tk.LEFT, padx=10)

        f_top2 = tk.Frame(self.root, pady=5)
        f_top2.pack(fill=tk.X, padx=10)

        self.var_mode = tk.StringVar(value="BLACK")
        tk.Label(f_top2, text="æ¨¡å¼:", font=("å¾®è½¯é›…é»‘", 10, "bold")).pack(side=tk.LEFT)
        tk.Radiobutton(f_top2, text="TWST (é»‘å­—)", variable=self.var_mode, value="BLACK").pack(side=tk.LEFT)
        tk.Radiobutton(f_top2, text="18TRIP (ç™½å­—)", variable=self.var_mode, value="WHITE").pack(side=tk.LEFT, padx=10)

        self.var_ocr = tk.BooleanVar(value=False)
        cb_ocr = tk.Checkbutton(f_top2, text="å¯ç”¨ OCR", variable=self.var_ocr, font=("å¾®è½¯é›…é»‘", 10, "bold"), fg="purple")
        cb_ocr.pack(side=tk.LEFT, padx=20)
        if not HAS_WIN_OCR:
            cb_ocr.config(state=tk.DISABLED, text="OCRä¸å¯ç”¨")

        self.btn_run = tk.Button(f_top2, text="â–¶ï¸ å¼€å§‹å¤„ç†", command=self.start_task, bg="#ddffdd", font=("å¾®è½¯é›…é»‘", 11, "bold"))
        self.btn_run.pack(side=tk.RIGHT)
        self.btn_stop = tk.Button(f_top2, text="ğŸ›‘ åœæ­¢", command=self.stop_task, bg="#ffdddd", font=("å¾®è½¯é›…é»‘", 11), state=tk.DISABLED)
        self.btn_stop.pack(side=tk.RIGHT, padx=10)

        f_mid = tk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        f_mid.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)

        self.canvas_frame = tk.Frame(f_mid, bg="#222")
        f_mid.add(self.canvas_frame, stretch="always")
        self.canvas = tk.Canvas(self.canvas_frame, bg="black")
        self.canvas.pack(fill=tk.BOTH, expand=True)

        f_log = tk.Frame(f_mid)
        f_mid.add(f_log, width=380)
        tk.Label(f_log, text="ğŸ“œ è¿è¡Œæ—¥å¿—").pack(anchor="w")
        self.txt_log = tk.Text(f_log, bg="#1e1e1e", fg="#00ff00", font=("Consolas", 9), state=tk.DISABLED)
        self.txt_log.pack(fill=tk.BOTH, expand=True)

        f_ctrl = tk.Frame(self.root, height=150)
        f_ctrl.pack(fill=tk.X, padx=10, pady=5)

        nb = ttk.Notebook(f_ctrl)
        nb.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        self.create_tab(nb, "å¯¹è¯æ¡†(ç»¿)", self.rect_d, 0)
        self.create_tab(nb, "é€‰é¡¹æ¡†(è“)", self.rect_c, 1)
        self.create_tab(nb, "èƒŒæ™¯(çº¢)", self.rect_b, 2)

        f_sets = tk.LabelFrame(f_ctrl, text="è®¾ç½®", padx=5)
        f_sets.pack(side=tk.RIGHT, fill=tk.Y, padx=5)

        tk.Label(f_sets, text="é˜²è¿è¯»çµæ•åº¦:").pack(anchor="w")
        self.s_diff = tk.Scale(f_sets, from_=0.1, to=10.0, resolution=0.1, orient=tk.HORIZONTAL)
        self.s_diff.set(3.0)
        self.s_diff.pack(fill=tk.X)

        tk.Label(f_sets, text="æ–‡å­—/è¾¹ç¼˜ é˜ˆå€¼:").pack(anchor="w")
        self.s_bin = tk.Scale(f_sets, from_=50, to=255, orient=tk.HORIZONTAL, command=self.update_preview)
        self.s_bin.set(130)
        self.s_bin.pack(fill=tk.X)

        f_bot = tk.Frame(self.root)
        f_bot.pack(side=tk.BOTTOM, fill=tk.X, padx=10, pady=10)
        self.s_time = tk.Scale(f_bot, from_=0, to=100, orient=tk.HORIZONTAL, showvalue=0, command=self.on_seek)
        self.s_time.pack(fill=tk.X)
        self.progress = ttk.Progressbar(f_bot, mode='determinate')
        self.progress.pack(fill=tk.X, pady=5)

    def create_tab(self, nb, title, rect_var, rid):
        f = tk.Frame(nb)
        nb.add(f, text=title)
        self.sliders = getattr(self, "sliders", {})
        if rid not in self.sliders:
            self.sliders[rid] =[]
        labels = ["X", "Y", "W", "H"]
        for i in range(4):
            tk.Label(f, text=labels[i]).pack(side=tk.LEFT, padx=2)
            s = tk.Scale(f, from_=0, to=2000, orient=tk.HORIZONTAL, command=lambda v, x=i, r=rid: self.on_rect(v, x, r))
            s.set(rect_var[i])
            s.pack(side=tk.LEFT, fill=tk.X, expand=True)
            self.sliders[rid].append(s)

    def on_rect(self, val, idx, rid):
        val = int(float(val))
        if rid == 0:
            self.rect_d[idx] = val
        elif rid == 1:
            self.rect_c[idx] = val
        elif rid == 2:
            self.rect_b[idx] = val
        self.update_preview()

    def load_video(self):
        path = filedialog.askopenfilename()
        if not path:
            return
        self.video_path = path
        self.cap = cv2.VideoCapture(path)
        self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
        self.fps = self.cap.get(cv2.CAP_PROP_FPS)
        w = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        h = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        self.s_time.config(to=self.total_frames)
        self.lbl_info.config(text=f"{os.path.basename(path)} ({w}x{h})")
        for slist in self.sliders.values():
            for s in slist:
                s.config(to=max(w, h))
        self.update_preview()

    def on_seek(self, val):
        self.update_preview()

    def update_preview(self, _=None):
        if not self.cap or self.is_processing:
            return
        self.cap.set(cv2.CAP_PROP_POS_FRAMES, int(self.s_time.get()))
        ret, frame = self.cap.read()
        if ret:
            x, y, w, h = self.rect_d
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
            xc, yc, wc, hc = self.rect_c
            cv2.rectangle(frame, (xc, yc), (xc+wc, yc+hc), (255, 255, 0), 2)
            xb, yb, wb, hb = self.rect_b
            cv2.rectangle(frame, (xb, yb), (xb+wb, yb+hb), (0, 0, 255), 2)

            roi = frame[y:y+h, x:x+w]
            if roi.size > 0:
                gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
                mode = cv2.THRESH_BINARY_INV if self.var_mode.get() == "BLACK" else cv2.THRESH_BINARY
                _, bin_img = cv2.threshold(gray, self.s_bin.get(), 255, mode)
                bin_c = cv2.cvtColor(bin_img, cv2.COLOR_GRAY2BGR)
                frame[y:y+h, x:x+w] = cv2.addWeighted(roi, 0.3, bin_c, 0.7, 0)

            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = Image.fromarray(frame)
            cw, ch = self.canvas.winfo_width(), self.canvas.winfo_height()
            if cw > 1:
                img.thumbnail((cw, ch))
            self.photo = ImageTk.PhotoImage(img)
            self.canvas.create_image(cw//2, ch//2, image=self.photo, anchor=tk.CENTER)

    def stop_task(self):
        self.is_processing = False
        self.log("âš ï¸ æ”¶åˆ°åœæ­¢æŒ‡ä»¤ï¼Œæ­£åœ¨å®‰å…¨é€€å‡º...")

    def start_task(self):
        if not self.video_path:
            return
        self.is_processing = True
        self.btn_run.config(state=tk.DISABLED, text="å¤„ç†ä¸­...")
        self.btn_stop.config(state=tk.NORMAL)
        self.log("\nğŸš€ === V12 å¼€å§‹æå– ===")
        threading.Thread(target=self.run_process, daemon=True).start()

    def run_process(self):
        try:
            p_rect_d = list(self.rect_d)
            p_rect_c = list(self.rect_c)
            p_rect_b = list(self.rect_b)
            p_diff = self.s_diff.get() / 100.0
            p_bin = self.s_bin.get()
            do_ocr = self.var_ocr.get()
            is_twst_mode = (self.var_mode.get() == "BLACK")
            
            LOWER_COLOR = np.array([0, 0, 100])
            UPPER_COLOR = np.array([180, 100, 255])

            cap = cv2.VideoCapture(self.video_path)
            total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            subs =[]

            # --- å¯¹è¯è½¨é“å˜é‡ ---
            d_speaking = False
            d_start = 0
            d_peak = 0.0
            d_best_frame = None
            d_max_den = 0.0
            last_dil_d = None

            # --- é€‰é¡¹è½¨é“å˜é‡ (V12 ç»å¯¹é™æ­¢æ£€æµ‹å™¨) ---
            c_active = False
            c_start = 0
            c_empty_frames = 0
            
            # å¿«é—¨æœºåˆ¶ç›¸å…³
            c_locked = False        # æ˜¯å¦å·²ç»æ‹åˆ°äº†å®Œç¾é™æ­¢çš„ç›¸ç‰‡
            c_best_frame = None     # é”æ­»çš„æœ€å®Œç¾æˆªå›¾
            c_fallback_frame = None # ä¿åº•æˆªå›¾ï¼ˆé˜²æ­¢æ‰‹é€Ÿå¤ªå¿«æ²¡æ¥å¾—åŠé™æ­¢ï¼‰
            c_max_den = 0.0         # ç”¨äºä¿åº•
            c_still_frames = 0      # é™æ­¢è®¡æ•°å™¨
            last_dil_c = None

            kernel = np.ones((3, 3), np.uint8)
            idx = 0

            while self.is_processing:
                ret, frame = cap.read()
                if not ret: break

                if idx % 100 == 0:
                    prog = (idx / total) * 100
                    self.root.after(0, lambda v=prog: self.progress.config(value=v))

                hsv_full = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
                
                # ========================================================
                # ğŸŸ¢ è½¨é“Aï¼šå¯¹è¯ (ä¿ç•™æ™ºèƒ½ç¼åˆé€»è¾‘)
                # ========================================================
                x, y, w, h = p_rect_d
                density_d = 0.0
                diff_score_d = 0.0
                dilated_d = None
                
                if w > 0 and h > 0:
                    roi_d = frame[y:y+h, x:x+w]
                    if is_twst_mode:
                        roi_d_hsv = hsv_full[y:y+h, x:x+w]
                        ratio_d = cv2.countNonZero(cv2.inRange(roi_d_hsv, LOWER_COLOR, UPPER_COLOR)) / (w * h)
                        if ratio_d > 0.4:
                            roi_gray = cv2.cvtColor(roi_d, cv2.COLOR_BGR2GRAY)
                            _, binary = cv2.threshold(roi_gray, 150, 255, cv2.THRESH_BINARY_INV)
                            dilated_d = cv2.dilate(binary, kernel, iterations=1)
                            density_d = cv2.countNonZero(dilated_d) / (w * h)
                    else:
                        roi_gray = cv2.cvtColor(roi_d, cv2.COLOR_BGR2GRAY)
                        _, binary = cv2.threshold(roi_gray, p_bin, 255, cv2.THRESH_BINARY)
                        dilated_d = cv2.dilate(binary, kernel, iterations=1)
                        density_d = cv2.countNonZero(dilated_d) / (w * h)

                    if dilated_d is not None:
                        if last_dil_d is not None:
                            diff_score_d = cv2.countNonZero(cv2.absdiff(dilated_d, last_dil_d)) / (w * h)
                        last_dil_d = dilated_d.copy()
                    else:
                        last_dil_d = None

                if not d_speaking:
                    if density_d > 0.005:
                        d_speaking = True
                        d_start = idx
                        d_peak = density_d
                        d_max_den = density_d
                        d_best_frame = roi_d.copy()
                else:
                    if density_d > d_peak: d_peak = density_d
                    if density_d > d_max_den + 0.001:
                        d_max_den = density_d
                        d_best_frame = roi_d.copy()

                    should_cut = False
                    if density_d < 0.003: should_cut = True
                    elif density_d < (d_peak * 0.4) and d_peak > 0.02: should_cut = True
                    elif diff_score_d > p_diff and (idx - d_start) / self.fps > 0.2: should_cut = True

                    if should_cut:
                        dur = (idx - d_start) / self.fps
                        if dur > 0.25:
                            st = datetime.timedelta(seconds=d_start / self.fps)
                            et = datetime.timedelta(seconds=idx / self.fps)
                            content = "Line [Dialog]"
                            
                            if do_ocr and d_best_frame is not None:
                                try:
                                    text = self.processor.ocr_image(d_best_frame)
                                    if text and len(text.strip()) >= 2: content = text.strip()
                                except: pass

                            # æ™ºèƒ½ç¼åˆé˜²é‡å½±
                            is_merged = False
                            if len(subs) > 0:
                                last_sub = subs[-1]
                                if content != "Line [Dialog]" and content == last_sub.content:
                                    last_sub.end = et
                                    is_merged = True
                                    self.log(f"ğŸ”„ ç¼åˆå¯¹è¯ç¢ç‰‡: {content[:10]}...")

                            if not is_merged:
                                subs.append(srt.Subtitle(index=0, start=st, end=et, content=content))
                                self.log(f"âœ… å¯¹è¯: {content[:15]}...")

                        if density_d > 0.005:
                            d_speaking = True
                            d_start = idx
                            d_peak = density_d
                            d_max_den = density_d
                            d_best_frame = roi_d.copy()
                        else:
                            d_speaking = False

                # ========================================================
                # ğŸ”µ è½¨é“Bï¼šé€‰é¡¹ (V12æ ¸å¿ƒ: ç»å¯¹é™æ­¢ä¾¦æµ‹)
                # ========================================================
                xc, yc, wc, hc = p_rect_c
                xb, yb, wb, hb = p_rect_b
                is_choice = False
                density_c = 0.0
                diff_score_c = 0.0
                dilated_c = None
                
                if wc > 0 and hc > 0:
                    roi_c = frame[yc:yc+hc, xc:xc+wc]
                    
                    if is_twst_mode:
                        # ä¾æ—§ä½¿ç”¨ç±³è‰²åº•æ¡†å®šä½
                        roi_c_hsv = hsv_full[yc:yc+hc, xc:xc+wc]
                        ratio_c = cv2.countNonZero(cv2.inRange(roi_c_hsv, LOWER_COLOR, UPPER_COLOR)) / (wc * hc)
                        
                        ratio_b = 0
                        if wb > 0 and hb > 0:
                            roi_b_hsv = hsv_full[yb:yb+hb, xb:xb+wb]
                            ratio_b = cv2.countNonZero(cv2.inRange(roi_b_hsv, LOWER_COLOR, UPPER_COLOR)) / (wb * hb)
                        
                        if (ratio_c > 0.4) and (ratio_c > ratio_b + 0.1):
                            gray_c = cv2.cvtColor(roi_c, cv2.COLOR_BGR2GRAY)
                            _, bin_c = cv2.threshold(gray_c, 150, 255, cv2.THRESH_BINARY_INV)
                            dilated_c = cv2.dilate(bin_c, kernel, iterations=1)
                            density_c = cv2.countNonZero(dilated_c) / (wc * hc)
                            if density_c > 0.005: 
                                is_choice = True
                    else:
                        gray_c = cv2.cvtColor(roi_c, cv2.COLOR_BGR2GRAY)
                        _, bin_c = cv2.threshold(gray_c, p_bin, 255, cv2.THRESH_BINARY)
                        dilated_c = cv2.dilate(bin_c, kernel, iterations=1)
                        density_c = cv2.countNonZero(dilated_c) / (wc * hc)
                        if density_c > 0.01:
                            is_choice = True

                    if dilated_c is not None:
                        if last_dil_c is not None:
                            diff_score_c = cv2.countNonZero(cv2.absdiff(dilated_c, last_dil_c)) / (wc * hc)
                        last_dil_c = dilated_c.copy()
                    else:
                        last_dil_c = None

                # é€‰é¡¹çŠ¶æ€æœº
                if not c_active:
                    if is_choice:
                        # é€‰é¡¹åˆšå¼¹å‡ºæ¥
                        c_active = True
                        c_start = idx
                        c_empty_frames = 0
                        c_locked = False
                        c_best_frame = None
                        c_still_frames = 0
                        c_max_den = density_c
                        c_fallback_frame = roi_c.copy() # ç¬¬ä¸€å¸§ä¿åº•
                else:
                    if is_choice:
                        c_empty_frames = 0 
                        
                        # éšæ—¶æ›´æ–°ä¿åº•æœ€é«˜å¯†åº¦å¸§
                        if density_c > c_max_den:
                            c_max_den = density_c
                            if not c_locked:
                                c_fallback_frame = roi_c.copy()

                        # ğŸ“· å¿«é—¨é€»è¾‘ï¼šå¯»æ‰¾ç»å¯¹é™æ­¢çš„é‚£ä¸€åˆ»
                        if not c_locked:
                            # åˆ¤å®šæ¡ä»¶ï¼šè¯¯å·®å°äº 0.1% è§†ä¸ºé™æ­¢ (å±è”½mp4å‹ç¼©çš„å¾®å°åƒç´ æŠ–åŠ¨)
                            if diff_score_c < 0.001:
                                c_still_frames += 1
                                # è¿ç»­ 8 å¸§ (çº¦ 0.25 ç§’) ç”»é¢çº¹ä¸ä¸åŠ¨
                                if c_still_frames >= 8:
                                    c_best_frame = roi_c.copy() # å’”åš“ï¼ä¸Šé”ï¼
                                    c_locked = True
                                    self.log(f"ğŸ“¸[é€‰é¡¹å¿«é—¨] å‘ç°å®Œç¾é™æ­¢ç”»é¢ï¼Œé”å®šï¼")
                            else:
                                # åªè¦åŠ¨äº†ä¸€ä¸‹ï¼ˆåŠ¨ç”»è¿˜æ²¡æ”¾å®Œ/ç©å®¶ç‚¹äº†ï¼‰ï¼Œé‡æ–°å€’æ•°
                                c_still_frames = 0
                    else:
                        # é€‰é¡¹æ¶ˆå¤±äº†
                        c_empty_frames += 1
                        if c_empty_frames > 15: # å®¹å¿ 0.5 ç§’çš„æ¶ˆå¤±åŠ¨ç”»
                            c_active = False
                            real_end_idx = idx - 15
                            dur_c = (real_end_idx - c_start) / self.fps
                            
                            if dur_c > 0.5:
                                st_c = datetime.timedelta(seconds=c_start / self.fps)
                                et_c = datetime.timedelta(seconds=real_end_idx / self.fps)
                                content_c = "Line [Choice]"
                                
                                # å–å›¾ç­–ç•¥ï¼šå¦‚æœæˆåŠŸé”å®šäº†é™æ­¢å¸§å°±ç”¨é™æ­¢å¸§ï¼Œå¦åˆ™è¯´æ˜ç©å®¶æ‰‹é€Ÿå¤ªå¿«ï¼Œç”¨ä¿åº•æœ€é«˜å¯†åº¦å¸§
                                target_frame = c_best_frame if c_locked else c_fallback_frame
                                
                                if do_ocr and target_frame is not None:
                                    try:
                                        text_c = self.processor.ocr_image(target_frame)
                                        if text_c and len(text_c.strip()) >= 2:
                                            content_c = f"{text_c.strip()} [Choice]"
                                    except: pass

                                # é€‰é¡¹ç¼åˆ
                                is_merged_c = False
                                if len(subs) > 0:
                                    last_sub = subs[-1]
                                    if content_c != "Line [Choice]" and content_c == last_sub.content:
                                        last_sub.end = et_c
                                        is_merged_c = True
                                        self.log(f"ğŸ”„ ç¼åˆé€‰é¡¹ç¢ç‰‡: {content_c[:10]}...")

                                if not is_merged_c:
                                    subs.append(srt.Subtitle(index=0, start=st_c, end=et_c, content=content_c))
                                    self.log(f"ğŸ”¹ é€‰é¡¹ç»“ç®—: {content_c[:15]}...")

                idx += 1

            cap.release()

            # --- æœ€åæ•´ç†åºå· ---
            subs.sort(key=lambda x: x.start)
            for i, sub in enumerate(subs):
                if sub.content == "Line [Dialog]": sub.content = f"Line {i+1}"
                elif sub.content == "Line [Choice]": sub.content = f"Line {i+1} [Choice]"
                sub.index = i + 1

            srt_path = os.path.splitext(self.video_path)[0] + ("_OCR.srt" if do_ocr else ".srt")
            with open(srt_path, "w", encoding="utf-8-sig") as f:
                f.write(srt.compose(subs))

            self.root.after(0, lambda: messagebox.showinfo("å®Œæˆ", f"ä»»åŠ¡æˆåŠŸï¼\næ–‡ä»¶å·²ä¿å­˜è‡³:\n{srt_path}"))

        except Exception as e:
            self.log(f"âŒ [è‡´å‘½é”™è¯¯] {str(e)}")
            print(traceback.format_exc())
        finally:
            self.is_processing = False
            self.root.after(0, lambda: self.btn_run.config(state=tk.NORMAL, text="â–¶ï¸ å¼€å§‹å¤„ç†"))

if __name__ == "__main__":
    root = tk.Tk()
    app = App(root)
    root.mainloop()
